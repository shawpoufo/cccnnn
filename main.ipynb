{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29cf37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 08:23:46.779502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 08:23:46.965896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitah/.local/share/virtualenvs/AIControle-oGQ6uKds/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-01-09 08:23:46.965926: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 08:23:48.011760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitah/.local/share/virtualenvs/AIControle-oGQ6uKds/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-01-09 08:23:48.011865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitah/.local/share/virtualenvs/AIControle-oGQ6uKds/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-01-09 08:23:48.011876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:08] \"GET / HTTP/1.1\" 200 -\n",
      "2023-01-09 08:24:11.021223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mitah/.local/share/virtualenvs/AIControle-oGQ6uKds/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-01-09 08:24:11.021258: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-09 08:24:11.021278: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mitah-ThinkPad-Edge-E540): /proc/driver/nvidia/version does not exist\n",
      "2023-01-09 08:24:11.021545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:12] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:12] \"GET /static/uploads/O_13954.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:20] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:20] \"GET /static/uploads/R_11036.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:24] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:24] \"GET /static/uploads/R_11054.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:29] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:29] \"GET /static/uploads/R_11085.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f98a57a7670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 111ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:35] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:35] \"GET /static/uploads/R_11081.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f98a56fc820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 118ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:42] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:42] \"GET /static/uploads/O_13845.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:46] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:46] \"GET /static/uploads/O_13948.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:50] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:50] \"GET /static/uploads/O_13806.jpg HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 129ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Jan/2023 08:24:57] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Jan/2023 08:24:57] \"GET /static/uploads/O_13920.jpg HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "from PIL import Image\n",
    "import os, io, sys\n",
    "import numpy as np\n",
    "from static.Models.RecyclableModel import create_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "UPLOAD_FOLDER = os.path.join('static', 'uploads')\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def upload():\n",
    "    img = request.files['image']\n",
    "\n",
    "    img_filename = img.filename\n",
    "    img.save(os.path.join(UPLOAD_FOLDER, img_filename))\n",
    "\n",
    "\n",
    "    acc = predict(img_filename)\n",
    "    \n",
    "\n",
    "    return render_template(\"index.html\", imagePath=img_filename,accuracy=acc)\n",
    "\n",
    "\n",
    "def predict(img):\n",
    "    #model = create_model()\n",
    "    model = load_model(os.path.join('static','Models','model.h5'))\n",
    "    img = cv2.imread(UPLOAD_FOLDER+\"/\" + img)\n",
    "\n",
    "    resize = tf.image.resize(img, (150, 150))\n",
    "\n",
    "    return model.predict(np.expand_dims(resize/255, 0))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f7d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('static', 'uploads','h.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1cf5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
